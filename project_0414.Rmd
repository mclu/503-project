---
title: "project_0414"
author: "Ting-Wei Lin"
date: "4/14/2020"
output: pdf_document
---

##Logistic Regression

### Data
Joint two datasets, trump tweets and s&p.

s&p: "delta1" equals to 0 means compared to the previous day the Adj.close is lower, and 1 otherwise.

"mc" equals to 0 means compared to ten days before Adj.close fluctuated less than 5%, and 1 otherwise.
```{r, echo = FALSE, message=FALSE, warning=FALSE}
library(dplyr)

tweet = read.csv("/Users/Sabrina/Documents/2019UMICH/STATS503/project/data/grouped_date_new.csv")
sp = read.csv("/Users/Sabrina/Documents/2019UMICH/STATS503/project/data/sp_indicator.csv")

tweet = 
  tweet %>% 
  rename(Date = date)

join = 
  tweet %>%
  left_join(sp, by = "Date")

join_rmna = join[complete.cases(join), ]

join_rmna$delta_day1 = factor(join_rmna$delta_day1)
join_rmna$delta_day2 = factor(join_rmna$delta_day2)
join_rmna$delta_day5 = factor(join_rmna$delta_day5)
join_rmna$delta_day10 = factor(join_rmna$delta_day10)
join_rmna$mc3 = factor(join_rmna$mc3) # mc: massive change
join_rmna$mc5 = factor(join_rmna$mc5)

set.seed(123)

n = dim(join_rmna)[1]
train_id = sample(seq(1, n, 1), floor(n*0.7))
test = join_rmna[-train_id, ]
train = join_rmna[train_id, ]

select_variables = c("retweets", "favorites", "ss_compound")
```

###Fit logistic model

Stock price rise or fall in the next day
```{r}
##### lag = 1
pairs(train[, select_variables], col=c("green","red")[train$delta_day1], 
      pch=c(1,2)[train$delta_day1])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$delta_day1)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_log1 = glm(delta_day1 ~ retweets + favorites + ss_compound,
              data = train, family = binomial)
summary(mod_log1)
```

Stock price rise or fall in the next two days
```{r}
##### lag = 2
pairs(train[, select_variables], col=c("green","red")[train$delta_day2], 
      pch=c(1,2)[train$delta_day2])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$delta_day2)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_log2 = glm(delta_day2 ~ retweets + favorites + ss_compound,
              data = train, family = binomial)
summary(mod_log2)
```

Stock price rise or fall in the next five days
```{r}

##### lag = 5
pairs(train[, select_variables], col=c("green","red")[train$delta_day5], 
      pch=c(1,2)[train$delta_day5])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$delta_day5)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_log5 = glm(delta_day5 ~ retweets + favorites + ss_compound,
               data = train, family = binomial)
summary(mod_log5)
```

Stock price rise or fall in the next ten days
```{r}
##### lag = 10
pairs(train[, select_variables], col=c("green","red")[train$delta_day10], 
      pch=c(1,2)[train$delta_day10])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$delta_day10)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_log10 = glm(delta_day10 ~ retweets + favorites + ss_compound,
               data = train, family = binomial)
summary(mod_log10)

```

Stock price has a massive change (>3%) in ten days

```{r}
##### lag = 10
pairs(train[, select_variables], col=c("green","red")[train$mc3], 
      pch=c(1,2)[train$mc3])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$mc3)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_logmc3 = glm(mc3 ~ retweets + favorites + ss_compound,
               data = train, family = binomial)
summary(mod_logmc3)
```

Stock price has a massive change (>5%) in ten days

```{r}
##### lag = 10
pairs(train[, select_variables], col=c("green","red")[train$mc5], 
      pch=c(1,2)[train$mc5])

par(xpd=TRUE)
legend(0.34, 0.51, as.vector(unique(train$mc5)), 
       col=c("green", "red"), pch=1:3, cex = 0.5)
#0 stock price lower than previous day


mod_logmc5 = glm(mc5 ~ retweets + favorites + ss_compound,
               data = train, family = binomial)
summary(mod_logmc5)
```

###Prediction

I chose mc > 5% as a predictor to fit our test data.

```{r}
##Prediction using logistic regression
pred = predict(mod_logmc5, test[, select_variables])
head(pred)

predProbs = binomial()$linkinv(pred)
pred_log = rep("Decrease", nrow(test))


pred_log[predProbs > .5] = "Increase" 
table(pred_log, test$mc5)

err_log = sum(pred_log != test$mc5) / nrow(test)
err_log
```

Although some models may have significant variables which seem to fit well, the prediction is really bad.

##Kmeans Clustering

Since we can see there is a obvious boundary in the pairwise plots, and it is difficult to find a label to classify if the stock price will rise or fall so I tried to use kmeans clustering to classify data into two groups.

```{r}
library(dplyr)

tweet = read.csv("/Users/Sabrina/Documents/2019UMICH/STATS503/project/data/grouped_date_new.csv")
sp = read.csv("/Users/Sabrina/Documents/2019UMICH/STATS503/project/data/sp_indicator.csv")

tweet = 
  tweet %>% 
  rename(Date = date)

join = 
  tweet %>%
  left_join(sp, by = "Date")

join_rmna = join[complete.cases(join), ]

fav = join_rmna$favorites
retweets = join_rmna$retweets
ss = join_rmna$ss_compound

nrow(join_rmna)
x = matrix(c(retweets, ss),nrow = nrow(join_rmna))

y = matrix(c(fav, ss),nrow = nrow(join_rmna))

km.outx = kmeans(x, 2)
km.outy = kmeans(y, 2)

plot(x, col = (km.outx$cluster+1), xlab = "retweets", ylab = "ss_compound")
plot(y, col = (km.outy$cluster+1), xlab = "favorites", ylab = "ss_compound")

```

Although the data can be clearly seperated into two groups, the ss_compound seems to be a really bad predictors to predict fluctuation of stock price.